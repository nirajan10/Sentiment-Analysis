{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97f1ec6",
   "metadata": {},
   "source": [
    "# Task: Sentiment Analysis for Movie Reviews\n",
    "\n",
    "### Objective:\n",
    "Develop a robust machine learning model capable of accurately classifying movie\n",
    "reviews as positive or negative based on the textual content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0b6b2e",
   "metadata": {},
   "source": [
    "### About Dataset\n",
    "IMDB dataset having 50K movie reviews for natural language processing or Text analytics. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets.<br><br>\n",
    "**Link:** <a>https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38656af2",
   "metadata": {},
   "source": [
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8ecae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk, re, os, string, pickle\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77bdf7",
   "metadata": {},
   "source": [
    "#### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1770e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a965e",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b794a374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55cf7c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66cda6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c177cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "dataset['sentiment'].value_counts().plot(kind = 'bar', ax = ax, color = ['steelBlue', 'DarkOrange'])\n",
    "ax.set_title('Sentiment', fontsize = 18, fontweight = 'bold')\n",
    "ax.set_ylabel('Count', fontsize = 13)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ef3ad",
   "metadata": {},
   "source": [
    "There are two labels for our target columns and we can see our dataset is completely balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687a5ee0",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672902cc",
   "metadata": {},
   "source": [
    "Data cleaning process includes following tasks:<br>\n",
    "1. Removal of HTML contents.\n",
    "2. Removal of punctuations.\n",
    "3. Lowercasing the text.\n",
    "4. Removal of stopwords.\n",
    "5. Stemming/Lemmatization.\n",
    "6. Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bcede",
   "metadata": {},
   "source": [
    "Let's try to do data cleaning in single text data and then later apply it to all dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc15b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = dataset['review'][0]\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de72a6f",
   "metadata": {},
   "source": [
    "**1. Removal of HTML contents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f915bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(review, \"html.parser\")\n",
    "review = soup.get_text()\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1ba60",
   "metadata": {},
   "source": [
    "**2. Removal of punctuations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50f51992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One of the other reviewers has mentioned that after watching just   Oz episode you ll be hooked  They are right  as this is exactly what happened with me The first thing that struck me about Oz was its brutality and unflinching scenes of violence  which set in right from the word GO  Trust me  this is not a show for the faint hearted or timid  This show pulls no punches with regards to drugs  sex or violence  Its is hardcore  in the classic use of the word It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary  It focuses mainly on Emerald City  an experimental section of the prison where all the cells have glass fronts and face inwards  so privacy is not high on the agenda  Em City is home to many  Aryans  Muslims  gangstas  Latinos  Christians  Italians  Irish and more    so scuffles  death stares  dodgy dealings and shady agreements are never far away I would say the main appeal of the show is due to the fact that it goes where other shows wouldn t dare  Forget pretty pictures painted for mainstream audiences  forget charm  forget romance   OZ doesn t mess around  The first episode I ever saw struck me as so nasty it was surreal  I couldn t say I was ready for it  but as I watched more  I developed a taste for Oz  and got accustomed to the high levels of graphic violence  Not just violence  but injustice  crooked guards who ll be sold out for a nickel  inmates who ll kill on order and get away with it  well mannered  middle class inmates being turned into prison bitches due to their lack of street skills or prison experience  Watching Oz  you may become comfortable with what is uncomfortable viewing    thats if you can get in touch with your darker side '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63b480",
   "metadata": {},
   "source": [
    "**3. Lowercasing the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ef6464e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the other reviewers has mentioned that after watching just   oz episode you ll be hooked  they are right  as this is exactly what happened with me the first thing that struck me about oz was its brutality and unflinching scenes of violence  which set in right from the word go  trust me  this is not a show for the faint hearted or timid  this show pulls no punches with regards to drugs  sex or violence  its is hardcore  in the classic use of the word it is called oz as that is the nickname given to the oswald maximum security state penitentary  it focuses mainly on emerald city  an experimental section of the prison where all the cells have glass fronts and face inwards  so privacy is not high on the agenda  em city is home to many  aryans  muslims  gangstas  latinos  christians  italians  irish and more    so scuffles  death stares  dodgy dealings and shady agreements are never far away i would say the main appeal of the show is due to the fact that it goes where other shows wouldn t dare  forget pretty pictures painted for mainstream audiences  forget charm  forget romance   oz doesn t mess around  the first episode i ever saw struck me as so nasty it was surreal  i couldn t say i was ready for it  but as i watched more  i developed a taste for oz  and got accustomed to the high levels of graphic violence  not just violence  but injustice  crooked guards who ll be sold out for a nickel  inmates who ll kill on order and get away with it  well mannered  middle class inmates being turned into prison bitches due to their lack of street skills or prison experience  watching oz  you may become comfortable with what is uncomfortable viewing    thats if you can get in touch with your darker side '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.lower()\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a2c6a",
   "metadata": {},
   "source": [
    "**4. Removal of stopwords**<br><br>\n",
    "Splitting the words into list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d7578f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'you',\n",
       " 'll',\n",
       " 'be',\n",
       " 'hooked',\n",
       " 'they',\n",
       " 'are',\n",
       " 'right',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'with',\n",
       " 'me',\n",
       " 'the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'about',\n",
       " 'oz',\n",
       " 'was',\n",
       " 'its',\n",
       " 'brutality',\n",
       " 'and',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'violence',\n",
       " 'which',\n",
       " 'set',\n",
       " 'in',\n",
       " 'right',\n",
       " 'from',\n",
       " 'the',\n",
       " 'word',\n",
       " 'go',\n",
       " 'trust',\n",
       " 'me',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'show',\n",
       " 'for',\n",
       " 'the',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'or',\n",
       " 'timid',\n",
       " 'this',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'no',\n",
       " 'punches',\n",
       " 'with',\n",
       " 'regards',\n",
       " 'to',\n",
       " 'drugs',\n",
       " 'sex',\n",
       " 'or',\n",
       " 'violence',\n",
       " 'its',\n",
       " 'is',\n",
       " 'hardcore',\n",
       " 'in',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " 'it',\n",
       " 'is',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'as',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary',\n",
       " 'it',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'emerald',\n",
       " 'city',\n",
       " 'an',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prison',\n",
       " 'where',\n",
       " 'all',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'have',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'and',\n",
       " 'face',\n",
       " 'inwards',\n",
       " 'so',\n",
       " 'privacy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'high',\n",
       " 'on',\n",
       " 'the',\n",
       " 'agenda',\n",
       " 'em',\n",
       " 'city',\n",
       " 'is',\n",
       " 'home',\n",
       " 'to',\n",
       " 'many',\n",
       " 'aryans',\n",
       " 'muslims',\n",
       " 'gangstas',\n",
       " 'latinos',\n",
       " 'christians',\n",
       " 'italians',\n",
       " 'irish',\n",
       " 'and',\n",
       " 'more',\n",
       " 'so',\n",
       " 'scuffles',\n",
       " 'death',\n",
       " 'stares',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'and',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'are',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away',\n",
       " 'i',\n",
       " 'would',\n",
       " 'say',\n",
       " 'the',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'of',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'where',\n",
       " 'other',\n",
       " 'shows',\n",
       " 'wouldn',\n",
       " 't',\n",
       " 'dare',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'for',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " 'forget',\n",
       " 'charm',\n",
       " 'forget',\n",
       " 'romance',\n",
       " 'oz',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'mess',\n",
       " 'around',\n",
       " 'the',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'i',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'as',\n",
       " 'so',\n",
       " 'nasty',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surreal',\n",
       " 'i',\n",
       " 'couldn',\n",
       " 't',\n",
       " 'say',\n",
       " 'i',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'it',\n",
       " 'but',\n",
       " 'as',\n",
       " 'i',\n",
       " 'watched',\n",
       " 'more',\n",
       " 'i',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'taste',\n",
       " 'for',\n",
       " 'oz',\n",
       " 'and',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " 'not',\n",
       " 'just',\n",
       " 'violence',\n",
       " 'but',\n",
       " 'injustice',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " 'who',\n",
       " 'll',\n",
       " 'be',\n",
       " 'sold',\n",
       " 'out',\n",
       " 'for',\n",
       " 'a',\n",
       " 'nickel',\n",
       " 'inmates',\n",
       " 'who',\n",
       " 'll',\n",
       " 'kill',\n",
       " 'on',\n",
       " 'order',\n",
       " 'and',\n",
       " 'get',\n",
       " 'away',\n",
       " 'with',\n",
       " 'it',\n",
       " 'well',\n",
       " 'mannered',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'being',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'to',\n",
       " 'their',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'or',\n",
       " 'prison',\n",
       " 'experience',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'you',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'with',\n",
       " 'what',\n",
       " 'is',\n",
       " 'uncomfortable',\n",
       " 'viewing',\n",
       " 'thats',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'your',\n",
       " 'darker',\n",
       " 'side']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.split()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "348f60b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'reviewers',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'hooked',\n",
       " 'right',\n",
       " 'exactly',\n",
       " 'happened',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'violence',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'go',\n",
       " 'trust',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'timid',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'punches',\n",
       " 'regards',\n",
       " 'drugs',\n",
       " 'sex',\n",
       " 'violence',\n",
       " 'hardcore',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'emerald',\n",
       " 'city',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cells',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'face',\n",
       " 'inwards',\n",
       " 'privacy',\n",
       " 'high',\n",
       " 'agenda',\n",
       " 'em',\n",
       " 'city',\n",
       " 'home',\n",
       " 'many',\n",
       " 'aryans',\n",
       " 'muslims',\n",
       " 'gangstas',\n",
       " 'latinos',\n",
       " 'christians',\n",
       " 'italians',\n",
       " 'irish',\n",
       " 'scuffles',\n",
       " 'death',\n",
       " 'stares',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'goes',\n",
       " 'shows',\n",
       " 'dare',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " 'forget',\n",
       " 'charm',\n",
       " 'forget',\n",
       " 'romance',\n",
       " 'oz',\n",
       " 'mess',\n",
       " 'around',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasty',\n",
       " 'surreal',\n",
       " 'say',\n",
       " 'ready',\n",
       " 'watched',\n",
       " 'developed',\n",
       " 'taste',\n",
       " 'oz',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " 'violence',\n",
       " 'injustice',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " 'sold',\n",
       " 'nickel',\n",
       " 'inmates',\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " 'well',\n",
       " 'mannered',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'turned',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'prison',\n",
       " 'experience',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'uncomfortable',\n",
       " 'viewing',\n",
       " 'thats',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4a498",
   "metadata": {},
   "source": [
    "**5. Stemming/Lemmatization.**<br>\n",
    "We use lemmatization instead of stemming because lemmatization gives the actual meaning to the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0a78f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf913a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'reviewer',\n",
       " 'mention',\n",
       " 'watch',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'hook',\n",
       " 'right',\n",
       " 'exactly',\n",
       " 'happen',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'strike',\n",
       " 'oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scene',\n",
       " 'violence',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'go',\n",
       " 'trust',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'timid',\n",
       " 'show',\n",
       " 'pull',\n",
       " 'punch',\n",
       " 'regard',\n",
       " 'drug',\n",
       " 'sex',\n",
       " 'violence',\n",
       " 'hardcore',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word',\n",
       " 'call',\n",
       " 'oz',\n",
       " 'nickname',\n",
       " 'give',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary',\n",
       " 'focus',\n",
       " 'mainly',\n",
       " 'emerald',\n",
       " 'city',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cell',\n",
       " 'glass',\n",
       " 'front',\n",
       " 'face',\n",
       " 'inwards',\n",
       " 'privacy',\n",
       " 'high',\n",
       " 'agenda',\n",
       " 'em',\n",
       " 'city',\n",
       " 'home',\n",
       " 'many',\n",
       " 'aryan',\n",
       " 'muslim',\n",
       " 'gangstas',\n",
       " 'latinos',\n",
       " 'christian',\n",
       " 'italian',\n",
       " 'irish',\n",
       " 'scuffle',\n",
       " 'death',\n",
       " 'stare',\n",
       " 'dodgy',\n",
       " 'dealing',\n",
       " 'shady',\n",
       " 'agreement',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'go',\n",
       " 'show',\n",
       " 'dare',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'picture',\n",
       " 'paint',\n",
       " 'mainstream',\n",
       " 'audience',\n",
       " 'forget',\n",
       " 'charm',\n",
       " 'forget',\n",
       " 'romance',\n",
       " 'oz',\n",
       " 'mess',\n",
       " 'around',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasty',\n",
       " 'surreal',\n",
       " 'say',\n",
       " 'ready',\n",
       " 'watch',\n",
       " 'developed',\n",
       " 'taste',\n",
       " 'oz',\n",
       " 'get',\n",
       " 'accustomed',\n",
       " 'high',\n",
       " 'level',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " 'violence',\n",
       " 'injustice',\n",
       " 'crook',\n",
       " 'guard',\n",
       " 'sell',\n",
       " 'nickel',\n",
       " 'inmate',\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " 'well',\n",
       " 'mannered',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmate',\n",
       " 'turn',\n",
       " 'prison',\n",
       " 'bitch',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skill',\n",
       " 'prison',\n",
       " 'experience',\n",
       " 'watch',\n",
       " 'oz',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'uncomfortable',\n",
       " 'view',\n",
       " 'thats',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_and_tags = nltk.pos_tag(review)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "review = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in words_and_tags]\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da10da20",
   "metadata": {},
   "source": [
    "Finally, we merge the words in form a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5da44247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mention watch oz episode hook right exactly happen first thing strike oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word call oz nickname give oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home many aryan muslim gangstas latinos christian italian irish scuffle death stare dodgy dealing shady agreement never far away would say main appeal show due fact go show dare forget pretty picture paint mainstream audience forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watch developed taste oz get accustomed high level graphic violence violence injustice crook guard sell nickel inmate kill order get away well mannered middle class inmate turn prison bitch due lack street skill prison experience watch oz may become comfortable uncomfortable view thats get touch darker side'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9436265",
   "metadata": {},
   "source": [
    "**6. Vectorization**<br>\n",
    "Converting text into TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13913e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8777d013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.12356041, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.12356041, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.12356041, 0.06178021, 0.06178021,\n",
       "        0.12356041, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.12356041,\n",
       "        0.06178021, 0.18534062, 0.06178021, 0.06178021, 0.18534062,\n",
       "        0.06178021, 0.06178021, 0.12356041, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.12356041, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.12356041, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.37068124, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.18534062, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.12356041, 0.06178021, 0.06178021, 0.12356041, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.24712083, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.06178021, 0.06178021, 0.06178021,\n",
       "        0.06178021, 0.06178021, 0.24712083, 0.18534062, 0.06178021,\n",
       "        0.12356041, 0.06178021]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "review_tf_idf = tf_idf.fit_transform(corpus)\n",
    "\n",
    "review_tf_idf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cc4fe6",
   "metadata": {},
   "source": [
    "### Splitting dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b3f3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['review']\n",
    "y = dataset['sentiment']\n",
    "\n",
    "y = (y.replace({'positive': 1, 'negative': 0})).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea28b380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nirajan\\Desktop\\Artificial Intelligence\\Learning\\env\\lib\\site-packages\\bs4\\__init__.py:439: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    }
   ],
   "source": [
    "corpus_train = []\n",
    "corpus_test  = []\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    soup = BeautifulSoup(X_train.iloc[i], \"html.parser\")\n",
    "    review = soup.get_text()\n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    words_and_tags = nltk.pos_tag(review)\n",
    "    review = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in words_and_tags]\n",
    "    review = ' '.join(review)\n",
    "    corpus_train.append(review)\n",
    "    \n",
    "for j in range(X_test.shape[0]):\n",
    "    soup = BeautifulSoup(X_test.iloc[j], \"html.parser\")\n",
    "    review = soup.get_text()\n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    words_and_tags = nltk.pos_tag(review)\n",
    "    review = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in words_and_tags]\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d70bbe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "tfidf = tfidf_vec.fit(corpus_train)\n",
    "\n",
    "pickle.dump(tfidf, open('./model/tfidf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d2475f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = tfidf.transform(corpus_train)\n",
    "X_test_vec = tfidf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7adc14",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb67ceea",
   "metadata": {},
   "source": [
    "#### 1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "035aa8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 89.38000000000001%\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.87      0.89      5044\n",
      "    Positive       0.88      0.91      0.90      4956\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[4408  636]\n",
      " [ 426 4530]]\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = logistic_regression.predict(X_test_vec)\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print(f'Accuracy : {accuracy*100}%')\n",
    "print(f\"Classification Report: \\n {metrics.classification_report(y_test, y_pred,target_names=['Negative','Positive'])}\")\n",
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7e18175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Logistic Regression on Train_set is 92.91%.\n",
      "The accuracy of Logistic Regression on Test_set is 89.38%.\n"
     ]
    }
   ],
   "source": [
    "print(f'The accuracy of Logistic Regression on Train_set is {metrics.accuracy_score(y_train, logistic_regression.predict(X_train_vec))*100:.2f}%.')\n",
    "print(f'The accuracy of Logistic Regression on Test_set is {metrics.accuracy_score(y_test, logistic_regression.predict(X_test_vec))*100:.2f}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd183d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\model\\LR.pkl', 'wb') as file:\n",
    "    pickle.dump(logistic_regression, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5ab4123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END C=0.001, max_iter=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=100, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l1, solver=saga; total time=   0.3s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l1, solver=saga; total time=   0.3s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END C=0.001, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l2, solver=saga; total time=   1.2s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l2, solver=saga; total time=   1.2s\n",
      "[CV] END .....C=0.001, max_iter=100, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END .....C=0.001, max_iter=500, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   0.1s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l1, solver=saga; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   1.2s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   1.2s\n",
      "[CV] END ....C=0.001, max_iter=1000, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l1, solver=saga; total time=   1.0s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l1, solver=saga; total time=   0.7s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.01, max_iter=100, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.01, max_iter=100, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time=   1.0s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .C=0.01, max_iter=500, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.01, max_iter=500, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time=   0.8s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time=   0.8s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time=   1.0s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l1, solver=saga; total time=   0.8s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END .....C=0.01, max_iter=1000, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END .......C=0.1, max_iter=100, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=   1.4s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=   1.4s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..C=0.1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .......C=0.1, max_iter=500, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END .C=0.1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END ......C=0.1, max_iter=1000, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l1, solver=saga; total time=   9.1s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l1, solver=saga; total time=   8.4s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l1, solver=saga; total time=   9.7s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l1, solver=saga; total time=   9.4s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l1, solver=saga; total time=   8.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=100, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .........C=1, max_iter=100, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l1, solver=liblinear; total time=   0.3s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=   8.8s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=   9.1s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=   9.2s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  10.5s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l1, solver=saga; total time=  10.9s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ....C=1, max_iter=500, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END .........C=1, max_iter=500, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l1, solver=liblinear; total time=   0.4s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=   8.7s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=   9.3s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=   7.6s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=   9.5s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l1, solver=saga; total time=  10.0s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...C=1, max_iter=1000, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END ........C=1, max_iter=1000, penalty=l2, solver=saga; total time=   0.9s\n",
      "{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy : 89.39%\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.87      0.89      5044\n",
      "    Positive       0.88      0.91      0.90      4956\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[4409  635]\n",
      " [ 426 4530]]\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_CV_logistic = GridSearchCV(logistic_regression, grid, cv=5, scoring='accuracy', verbose=2)\n",
    "grid_CV_logistic.fit(X_train_vec, y_train)\n",
    "best_param = grid_CV_logistic.best_params_\n",
    "print(best_param)\n",
    "\n",
    "final_lr = grid_CV_logistic.best_estimator_\n",
    "y_pred = final_lr.predict(X_test_vec)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print(f'Accuracy : {accuracy*100}%')\n",
    "print(f\"Classification Report: \\n {metrics.classification_report(y_test, y_pred,target_names=['Negative','Positive'])}\")\n",
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "041dd4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Final LR on Train_set is 92.90%.\n",
      "The accuracy of Final LR on Test_set is 89.39%.\n"
     ]
    }
   ],
   "source": [
    "print(f'The accuracy of Final LR on Train_set is {metrics.accuracy_score(y_train, final_lr.predict(X_train_vec))*100:.2f}%.')\n",
    "print(f'The accuracy of Final LR on Test_set is {metrics.accuracy_score(y_test, final_lr.predict(X_test_vec))*100:.2f}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17685f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\model\\\\final_LR.pkl', 'wb') as file:\n",
    "    pickle.dump(final_lr, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ded68",
   "metadata": {},
   "source": [
    "#### 2. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4093642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 89.91%\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.89      0.90      5044\n",
      "    Positive       0.89      0.91      0.90      4956\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[4493  551]\n",
      " [ 458 4498]]\n"
     ]
    }
   ],
   "source": [
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = linear_svc.predict(X_test_vec)\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print(f'Accuracy : {accuracy*100}%')\n",
    "print(f\"Classification Report: \\n {metrics.classification_report(y_test, y_pred,target_names=['Negative','Positive'])}\")\n",
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fca7e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Linear SVC on Train_set is 98.30%.\n",
      "The accuracy of Linear SVC on Test_set is 89.91%.\n"
     ]
    }
   ],
   "source": [
    "print(f'The accuracy of Linear SVC on Train_set is {metrics.accuracy_score(y_train, linear_svc.predict(X_train_vec))*100:.2f}%.')\n",
    "print(f'The accuracy of Linear SVC on Test_set is {metrics.accuracy_score(y_test, linear_svc.predict(X_test_vec))*100:.2f}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9130a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\model\\linear_svc.pkl', 'wb') as file:\n",
    "    pickle.dump(linear_svc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdf5df0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=1000; total time=   0.2s\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=1000; total time=   0.0s\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=5000; total time=   0.0s\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=5000; total time=   0.0s\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=5000; total time=   0.0s\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=5000; total time=   0.0s\n",
      "[CV] END ..................C=0.01, loss=hinge, max_iter=5000; total time=   0.0s\n",
      "[CV] END .................C=0.01, loss=hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END .................C=0.01, loss=hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END .................C=0.01, loss=hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END .................C=0.01, loss=hinge, max_iter=10000; total time=   0.0s\n",
      "[CV] END .................C=0.01, loss=hinge, max_iter=10000; total time=   0.0s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ..........C=0.01, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END .........C=0.01, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END .........C=0.01, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END .........C=0.01, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END .........C=0.01, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END .........C=0.01, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=1000; total time=   0.0s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=5000; total time=   0.0s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ...................C=0.1, loss=hinge, max_iter=5000; total time=   0.2s\n",
      "[CV] END ..................C=0.1, loss=hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END ..................C=0.1, loss=hinge, max_iter=10000; total time=   0.3s\n",
      "[CV] END ..................C=0.1, loss=hinge, max_iter=10000; total time=   0.2s\n",
      "[CV] END ..................C=0.1, loss=hinge, max_iter=10000; total time=   0.3s\n",
      "[CV] END ..................C=0.1, loss=hinge, max_iter=10000; total time=   0.2s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=1000; total time=   0.4s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=1000; total time=   0.3s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=1000; total time=   0.3s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ...........C=0.1, loss=squared_hinge, max_iter=5000; total time=   0.1s\n",
      "[CV] END ..........C=0.1, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END ..........C=0.1, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END ..........C=0.1, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END ..........C=0.1, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END ..........C=0.1, loss=squared_hinge, max_iter=10000; total time=   0.1s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=1000; total time=   0.7s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=1000; total time=   1.9s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=1000; total time=   1.1s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=1000; total time=   0.2s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=1000; total time=   0.1s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=5000; total time=   0.2s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=5000; total time=   0.6s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=5000; total time=   0.4s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=5000; total time=   0.2s\n",
      "[CV] END ...................C=0.5, loss=hinge, max_iter=5000; total time=   0.2s\n",
      "[CV] END ..................C=0.5, loss=hinge, max_iter=10000; total time=   0.2s\n",
      "[CV] END ..................C=0.5, loss=hinge, max_iter=10000; total time=   1.3s\n",
      "[CV] END ..................C=0.5, loss=hinge, max_iter=10000; total time=   1.1s\n",
      "[CV] END ..................C=0.5, loss=hinge, max_iter=10000; total time=   0.3s\n",
      "[CV] END ..................C=0.5, loss=hinge, max_iter=10000; total time=   0.4s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=1000; total time=   0.4s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=1000; total time=   0.4s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=1000; total time=   0.4s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=1000; total time=   0.4s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=1000; total time=   0.4s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=5000; total time=   0.3s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=5000; total time=   0.3s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=5000; total time=   0.3s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=5000; total time=   0.3s\n",
      "[CV] END ...........C=0.5, loss=squared_hinge, max_iter=5000; total time=   0.3s\n",
      "[CV] END ..........C=0.5, loss=squared_hinge, max_iter=10000; total time=   0.3s\n",
      "[CV] END ..........C=0.5, loss=squared_hinge, max_iter=10000; total time=   0.3s\n",
      "[CV] END ..........C=0.5, loss=squared_hinge, max_iter=10000; total time=   0.3s\n",
      "[CV] END ..........C=0.5, loss=squared_hinge, max_iter=10000; total time=   0.4s\n",
      "[CV] END ..........C=0.5, loss=squared_hinge, max_iter=10000; total time=   0.3s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=1000; total time=   1.2s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=1000; total time=   1.1s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=1000; total time=   0.5s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=1000; total time=   0.5s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=1000; total time=   0.5s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=5000; total time=   1.1s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=5000; total time=   1.0s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=5000; total time=   0.5s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=5000; total time=   0.5s\n",
      "[CV] END .....................C=1, loss=hinge, max_iter=5000; total time=   0.5s\n",
      "[CV] END ....................C=1, loss=hinge, max_iter=10000; total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, loss=hinge, max_iter=10000; total time=   0.7s\n",
      "[CV] END ....................C=1, loss=hinge, max_iter=10000; total time=   0.5s\n",
      "[CV] END ....................C=1, loss=hinge, max_iter=10000; total time=   0.5s\n",
      "[CV] END ....................C=1, loss=hinge, max_iter=10000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=1000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=1000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=1000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=1000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=1000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=5000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=5000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=5000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=5000; total time=   0.5s\n",
      "[CV] END .............C=1, loss=squared_hinge, max_iter=5000; total time=   0.5s\n",
      "[CV] END ............C=1, loss=squared_hinge, max_iter=10000; total time=   0.5s\n",
      "[CV] END ............C=1, loss=squared_hinge, max_iter=10000; total time=   0.5s\n",
      "[CV] END ............C=1, loss=squared_hinge, max_iter=10000; total time=   0.5s\n",
      "[CV] END ............C=1, loss=squared_hinge, max_iter=10000; total time=   0.5s\n",
      "[CV] END ............C=1, loss=squared_hinge, max_iter=10000; total time=   0.5s\n",
      "{'C': 0.5, 'loss': 'squared_hinge', 'max_iter': 1000}\n",
      "Accuracy : 89.92%\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.89      0.90      5044\n",
      "    Positive       0.89      0.91      0.90      4956\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[4476  568]\n",
      " [ 440 4516]]\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    'C': [0.01, 0.1, 0.5, 1], \n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'max_iter': [1000, 5000, 10000]\n",
    "}\n",
    "\n",
    "grid_CV_svc = GridSearchCV(linear_svc, grid, cv=5, scoring='accuracy', verbose=2)\n",
    "grid_CV_svc.fit(X_train_vec, y_train)\n",
    "best_param = grid_CV_svc.best_params_\n",
    "print(best_param)\n",
    "\n",
    "final_svc = grid_CV_svc.best_estimator_\n",
    "y_pred = final_svc.predict(X_test_vec)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "print(f'Accuracy : {accuracy*100}%')\n",
    "print(f\"Classification Report: \\n {metrics.classification_report(y_test, y_pred,target_names=['Negative','Positive'])}\")\n",
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14a5b595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Final Linear SVC on Train_set is 96.97%.\n",
      "The accuracy of Final Linear SVC on Test_set is 89.92%.\n"
     ]
    }
   ],
   "source": [
    "print(f'The accuracy of Final Linear SVC on Train_set is {metrics.accuracy_score(y_train, final_svc.predict(X_train_vec))*100:.2f}%.')\n",
    "print(f'The accuracy of Final Linear SVC on Test_set is {metrics.accuracy_score(y_test, final_svc.predict(X_test_vec))*100:.2f}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7c05cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\model\\\\final_svc.pkl', 'wb') as file:\n",
    "    pickle.dump(final_svc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7e1b0",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "From the above two model, linear SVC is giving higher accuracy but the model is overfitted. So, the optimal model is final logistic regression which is less overfitted compared to linear SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "661b641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lr(text):\n",
    "    corpus = []\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    review = soup.get_text()\n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words_and_tags = nltk.pos_tag(review)\n",
    "    review = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in words_and_tags]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "    review_tf_idf = tfidf.transform(corpus)\n",
    "    review_tf_idf.toarray()\n",
    "    \n",
    "    output = final_lr.predict(review_tf_idf)\n",
    "\n",
    "    if output.item() == 1:\n",
    "        print('Positive')\n",
    "    else:\n",
    "        print('Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "16fdc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Starting was not that great but as the movie progressed, the story become more interesting.'\n",
    "text2 = 'This is not what I expected when I watched the trailor of the movie. The story is so generic.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b5bf2ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "predict_lr(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8a3cbca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "predict_lr(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de2a10f",
   "metadata": {},
   "source": [
    "This concludes the ML part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfdc542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
